{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "demonstrated-psychiatry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading environment football failed: No module named 'gfootball'\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from kaggle_environments.envs.hungry_geese.hungry_geese import Action, Configuration, Observation, histogram, translate, row_col\n",
    "from kaggle_environments import make as kaggle_make\n",
    "import tqdm\n",
    "\n",
    "from hungry_geese.env.torch_env import TorchEnv\n",
    "import hungry_geese.env.goose_env as ge\n",
    "#device = torch.device('cuda:0')\n",
    "device = torch.device('cpu')\n",
    "\n",
    "config = Configuration(kaggle_make('hungry_geese', debug=False).configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "democratic-smile",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 40/40 [00:00<00:00, 302.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 40\n",
      "Lengths: [1, 0, 0, 1]\n",
      "Rewards: [4001, 3901, 3901, 4001]\n",
      "\n",
      "_ _ * _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ A _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ D _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ * _ _ _\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test = TorchEnv(config, n_envs=100, obs_type=ge.ObsType.COMBINED_GRADIENT_OBS_LARGE, n_geese=4, device=device)\n",
    "\n",
    "moves = torch.zeros((test.n_envs, test.n_geese), dtype=torch.int64, device=device) + 1\n",
    "update_mask = torch.ones((test.n_envs,), dtype=torch.bool, device=device)\n",
    "update_mask[-1] = False\n",
    "\n",
    "profiling_enabled = False\n",
    "with torch.autograd.profiler.profile(enabled=profiling_enabled, use_cuda=True) as prof:\n",
    "    test.reset()\n",
    "    for i in tqdm.trange(40):\n",
    "        test.step(moves, update_mask)\n",
    "print(test.render_env(0, include_info=True))\n",
    "if profiling_enabled:\n",
    "    prof.export_chrome_trace(f'trace_{str(device).split(\":\")[0]}_{test.n_envs}_envs.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "comparable-bailey",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0\n",
      "Lengths: [1, 1, 1, 1]\n",
      "Rewards: [0, 0, 0, 0]\n",
      "\n",
      "_ _ _ _ A _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ *\n",
      "_ C _ * _ _ _ D _ _ _\n",
      "_ _ _ _ _ _ _ B _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(test.render_env(-1, include_info=True))\n",
    "test.obs[-1][test.obs_channel_idxs['steps_since_starvation']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identical-bibliography",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_level_events_only = True\n",
    "if torch.device == torch.device('cpu'):\n",
    "    print(prof.key_averages().table(sort_by=\"cpu_time_total\"))\n",
    "else:\n",
    "    print(prof.key_averages().table(sort_by=\"cuda_time_total\", top_level_events_only=top_level_events_only))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "central-thong",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_idx = 1\n",
    "test.geese_tensor[env_idx], test.lengths[env_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adolescent-ireland",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.dones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooperative-grass",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.geese[sc].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focal-federal",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.arange(8).view(2, 4) % torch.tensor([2, 3]).view(2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "natural-progress",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "test.geese[torch.arange(test.n_envs)[test.dones], :, 0] = 1\n",
    "test.geese.sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "creative-trouble",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_rows = 7\n",
    "n_cols = 11\n",
    "\n",
    "head_locs = torch.multinomial(\n",
    "    torch.ones((3, n_rows * n_cols)),\n",
    "    4\n",
    ")\n",
    "loc_to_row_column = torch.tensor(\n",
    "    [row_col(i, n_cols) for i in range(n_rows * n_cols)],\n",
    ").view(n_rows * n_cols, 2)\n",
    "loc_to_row_column[head_locs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immune-training",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kaggle_environments\n",
    "from kaggle_environments.envs.hungry_geese.hungry_geese import Action, Configuration, Observation\n",
    "\n",
    "from hungry_geese.utils import read_json\n",
    "from hungry_geese.env.lightweight_env import make_from_state\n",
    "import main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "golden-semiconductor",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_from_state(Observation(env.steps[-2][0]['observation']), [Action.NORTH] * 4).done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plain-subscription",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(env.steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infectious-senior",
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_dict = read_json('/home/isaiah/Downloads/19998794.json')\n",
    "env = kaggle_environments.make(\n",
    "    'hungry_geese',\n",
    "    configuration=replay_dict['configuration'],\n",
    "    steps=replay_dict['steps'],\n",
    "    info=replay_dict['info']\n",
    ")\n",
    "\n",
    "conf = env.configuration\n",
    "env.steps[119][0]['observation']['step'] = 0\n",
    "\n",
    "main.AGENT = None\n",
    "main.call_agent(env.steps[119][0]['observation'], conf)\n",
    "main.call_agent(env.steps[120][0]['observation'], conf)\n",
    "\"\"\"\n",
    "obs = Observation(Observation(env.steps[120][0]['observation']))\n",
    "main.AGENT.preprocess(obs, conf)\n",
    "light_env = make_from_state(obs, main.AGENT.last_actions)\n",
    "main.AGENT.search_tree.run_batch_mcts(light_env.lightweight_clone(), 1, n_iter=2)\n",
    "out = main.AGENT.search_tree.expand(light_env)\n",
    "out\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "harmful-general",
   "metadata": {},
   "outputs": [],
   "source": [
    "light_env.step_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaged-michigan",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(light_env.render_ansi())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fuzzy-nudist",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.render(mode='ipython', height=700, width=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continued-response",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_geese = 4\n",
    "values = torch.arange(8).view(2,4).to(torch.float)\n",
    "still_alive = torch.ones_like(values).to(torch.bool)\n",
    "still_alive[0,0:2] = False\n",
    "\n",
    "\n",
    "values.masked_fill_(~still_alive, float('-inf'))\n",
    "win_probs = torch.softmax(values, dim=-1)\n",
    "print(win_probs)\n",
    "remaining_rewards = torch.linspace(0., 1., n_geese, dtype=torch.float)\n",
    "remaining_rewards_min = remaining_rewards[-still_alive.sum(dim=-1)].unsqueeze(-1)\n",
    "remaining_rewards_var = 1. - remaining_rewards_min\n",
    "values = remaining_rewards_min + win_probs * remaining_rewards_var\n",
    "# TODO: This is a hacky solution - there should be a more elegant way to do this for any n_geese_remaining?\n",
    "print(values)\n",
    "values = torch.where(\n",
    "    still_alive.sum(dim=-1, keepdim=True) == 4,\n",
    "    values * 2.,\n",
    "    values\n",
    ")\n",
    "values = torch.where(\n",
    "    still_alive.sum(dim=-1, keepdim=True) == 3,\n",
    "    values * 1.2,\n",
    "    values\n",
    ")\n",
    "\n",
    "print(values)\n",
    "max_vals = values.max(dim=-1, keepdim=True)[0]\n",
    "values = torch.where(\n",
    "    max_vals > 1.,\n",
    "    torch.where(\n",
    "        values == max_vals,\n",
    "        values - (max_vals - 1.),\n",
    "        values + (max_vals - 1.) / still_alive.sum(dim=-1, keepdim=True)\n",
    "    ),\n",
    "    values\n",
    ")\n",
    "print(values)\n",
    "values * 2. - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approximate-sitting",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda')\n",
    "\n",
    "obs_type = ge.ObsType.COMBINED_GRADIENT_OBS\n",
    "n_channels = 128\n",
    "activation = nn.ReLU\n",
    "normalize = False\n",
    "model_kwargs = dict(\n",
    "    block_class=models.BasicConvolutionalBlock,\n",
    "    conv_block_kwargs=[\n",
    "        dict(\n",
    "            in_channels=obs_type.get_obs_spec()[-3],\n",
    "            out_channels=n_channels,\n",
    "            kernel_size=3,\n",
    "            activation=activation,\n",
    "            normalize=normalize\n",
    "        ),\n",
    "        dict(\n",
    "            in_channels=n_channels,\n",
    "            out_channels=n_channels,\n",
    "            kernel_size=3,\n",
    "            activation=activation,\n",
    "            normalize=normalize\n",
    "        ),\n",
    "        dict(\n",
    "            in_channels=n_channels,\n",
    "            out_channels=n_channels,\n",
    "            kernel_size=3,\n",
    "            activation=activation,\n",
    "            normalize=normalize\n",
    "        ),\n",
    "    ],\n",
    "    squeeze_excitation=True,\n",
    "    cross_normalize_value=True,\n",
    "    # **ge.RewardType.RANK_ON_DEATH.get_recommended_value_activation_scale_shift_dict()\n",
    ")\n",
    "model = models.FullConvActorCriticNetwork(**model_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "announced-elevation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import copy\n",
    "from kaggle_environments import make as kaggle_make\n",
    "from kaggle_environments.envs.hungry_geese.hungry_geese import Action, Configuration, Observation\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from scipy import special, stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.cuda import amp\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from hungry_geese import models\n",
    "from hungry_geese.utils import ActionMasking\n",
    "from hungry_geese.env import goose_env as ge\n",
    "from hungry_geese.env.lightweight_env import LightweightEnv, make_from_state\n",
    "from hungry_geese.mcts.basic_mcts import BasicMCTS\n",
    "from hungry_geese.training.alphagoose.alphagoose_data import AlphaGoosePretrainDataset, ToTensor\n",
    "from hungry_geese.utils import read_json\n",
    "\n",
    "%matplotlib inline\n",
    "DEVICE = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrong-investigator",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_type = ge.ObsType.COMBINED_GRADIENT_OBS\n",
    "n_channels = 64\n",
    "activation = nn.ReLU\n",
    "model_kwargs = dict(\n",
    "    block_class=models.BasicConvolutionalBlock,\n",
    "    conv_block_kwargs=[\n",
    "        dict(\n",
    "            in_channels=obs_type.get_obs_spec()[-3],\n",
    "            out_channels=n_channels,\n",
    "            kernel_size=3,\n",
    "            activation=activation,\n",
    "            normalize=False\n",
    "        ),\n",
    "        dict(\n",
    "            in_channels=n_channels,\n",
    "            out_channels=n_channels,\n",
    "            kernel_size=3,\n",
    "            activation=activation,\n",
    "            normalize=False\n",
    "        ),\n",
    "        dict(\n",
    "            in_channels=n_channels,\n",
    "            out_channels=n_channels,\n",
    "            kernel_size=3,\n",
    "            activation=activation,\n",
    "            normalize=False\n",
    "        ),\n",
    "        dict(\n",
    "            in_channels=n_channels,\n",
    "            out_channels=n_channels,\n",
    "            kernel_size=3,\n",
    "            activation=activation,\n",
    "            normalize=False\n",
    "        ),\n",
    "        dict(\n",
    "            in_channels=n_channels,\n",
    "            out_channels=n_channels,\n",
    "            kernel_size=3,\n",
    "            activation=activation,\n",
    "            normalize=False\n",
    "        ),\n",
    "    ],\n",
    "    squeeze_excitation=True,\n",
    "    cross_normalize_value=True,\n",
    "    # **ge.RewardType.RANK_ON_DEATH.get_recommended_value_activation_scale_shift_dict()\n",
    ")\n",
    "model = models.FullConvActorCriticNetwork(**model_kwargs)\n",
    "model.to(device=DEVICE)\n",
    "\n",
    "run_dir = Path('runs/supervised_pretraining/active/supervised_pretraining_combined_gradient_obs_rank_on_death_none_5_blocks_64_dims_v1/')\n",
    "with open(run_dir / '0070/cp.txt', 'r') as f:\n",
    "    serialized_string = f.readline()[2:-1].encode()\n",
    "state_dict_bytes = base64.b64decode(serialized_string)\n",
    "loaded_state_dicts = pickle.loads(state_dict_bytes)\n",
    "model.load_state_dict(loaded_state_dicts)\n",
    "\n",
    "def action_mask_func(state):\n",
    "    return ActionMasking.LETHAL.get_action_mask(state)\n",
    "    \n",
    "def terminal_value_func(state):\n",
    "    agent_rankings = stats.rankdata([agent['reward'] for agent in state], method='average') - 1.\n",
    "    ranks_rescaled = 2. * agent_rankings / (len(state) - 1.) - 1.\n",
    "    return ranks_rescaled\n",
    "    \n",
    "def actor_critic_func(state):\n",
    "    geese = state[0]['observation']['geese']\n",
    "    n_geese = len(geese)\n",
    "    \n",
    "    obs = ge.create_obs_tensor(state, obs_type)\n",
    "    head_locs = [goose[0] if len(goose) > 0 else -1 for goose in geese]\n",
    "    still_alive = [agent['status'] == 'ACTIVE' for agent in state]\n",
    "    with torch.no_grad():\n",
    "        logits, values = model(torch.from_numpy(obs),\n",
    "                               torch.tensor(head_locs).unsqueeze(0),\n",
    "                               torch.tensor(still_alive).unsqueeze(0))\n",
    "    \n",
    "    # Score the dead geese\n",
    "    dead_geese_mask = np.array([len(goose) for goose in geese]) == 0\n",
    "    agent_rankings = stats.rankdata([agent['reward'] for agent in state], method='average') - 1.\n",
    "    agent_rankings_rescaled = 2. * agent_rankings / (n_geese - 1.) - 1.\n",
    "    \n",
    "    logits = F.softmax(logits, -1)\n",
    "    final_values = np.where(\n",
    "        dead_geese_mask,\n",
    "        agent_rankings_rescaled,\n",
    "        values.squeeze(0).numpy()\n",
    "    )\n",
    "    \n",
    "    # Logits should be of shape (4, 4)\n",
    "    # Values should be of shape (4, 1)\n",
    "    return logits.squeeze(0).numpy().astype(np.float), final_values[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sudden-gabriel",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(run_dir / 'train_episodes.txt', 'r') as f:\n",
    "    train_episodes = [replay_name.rstrip() for replay_name in f.readlines()]\n",
    "    train_episodes = set(train_episodes)\n",
    "with open(run_dir / 'test_episodes.txt', 'r') as f:\n",
    "    test_episodes = [replay_name.rstrip() for replay_name in f.readlines()]\n",
    "    test_episodes = set(test_episodes)\n",
    "\n",
    "dataset_loc = Path('/home/isaiah/data/alphagoose_data_1000/')\n",
    "train_dataset = AlphaGoosePretrainDataset(\n",
    "    dataset_loc,\n",
    "    ge.ObsType.COMBINED_GRADIENT_OBS,\n",
    "    transform=ToTensor(),\n",
    "    include_episode=lambda x: x.stem in train_episodes\n",
    ")\n",
    "test_dataset = AlphaGoosePretrainDataset(\n",
    "    dataset_loc,\n",
    "    ge.ObsType.COMBINED_GRADIENT_OBS,\n",
    "    transform=ToTensor(),\n",
    "    include_episode=lambda x: x.stem in test_episodes\n",
    ")\n",
    "dataloader_kwargs = dict(\n",
    "    batch_size=512,\n",
    "    shuffle=True,\n",
    "    num_workers=6,\n",
    "    pin_memory=True\n",
    ")\n",
    "train_dataloader = DataLoader(train_dataset, **dataloader_kwargs)\n",
    "test_dataloader = DataLoader(test_dataset, **dataloader_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "allied-phenomenon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_losses(\n",
    "        state,\n",
    "        action,\n",
    "        result,\n",
    "        head_locs,\n",
    "        still_alive,\n",
    "        reduction='mean',\n",
    "        get_preds=False\n",
    "):\n",
    "    with amp.autocast():\n",
    "        logits, value = model(state, head_locs, still_alive)\n",
    "\n",
    "        logits_masked = logits.view(-1, 4)[still_alive.view(-1, 1).expand(-1, 4)].view(-1, 4)\n",
    "        action_masked = action.view(-1)[still_alive.view(-1)]\n",
    "        policy_loss = F.cross_entropy(logits_masked, action_masked, reduction=reduction)\n",
    "\n",
    "        value_masked = value.view(-1)[still_alive.view(-1)]\n",
    "        result_masked = result.view(-1)[still_alive.view(-1)]\n",
    "        value_loss = F.mse_loss(value_masked, result_masked, reduction=reduction)\n",
    "\n",
    "        probs_masked = F.softmax(logits_masked, dim=-1)\n",
    "        entropy_loss = torch.sum(probs_masked * torch.log(probs_masked), dim=-1)\n",
    "        if reduction == 'none':\n",
    "            pass\n",
    "        elif reduction == 'mean':\n",
    "            entropy_loss = entropy_loss.mean()\n",
    "        elif reduction == 'sum':\n",
    "            entropy_loss = entropy_loss.sum()\n",
    "        else:\n",
    "            raise ValueError(f'Unrecognized reduction: {reduction}')\n",
    "\n",
    "        combined_loss = policy_loss + value_loss + 0.05 * entropy_loss\n",
    "\n",
    "    if get_preds:\n",
    "        return policy_loss, value_loss, entropy_loss, combined_loss, logits_masked.argmax(dim=-1)\n",
    "    else:\n",
    "        return policy_loss, value_loss, entropy_loss, combined_loss\n",
    "\n",
    "test_metrics = {\n",
    "    'policy_loss': 0.,\n",
    "    'value_loss': 0.,\n",
    "    'entropy_loss': 0.,\n",
    "    'combined_loss': 0.,\n",
    "    'policy_accuracy': 0.\n",
    "}\n",
    "n_test_samples = 0.\n",
    "with torch.no_grad():\n",
    "    for test_tuple in tqdm(test_dataloader):\n",
    "        test_tuple = [t.to(device=DEVICE) for t in test_tuple]\n",
    "        state, action, result, head_locs, still_alive = test_tuple\n",
    "        policy_loss, value_loss, entropy_loss, combined_loss, preds = compute_losses(\n",
    "            *test_tuple,\n",
    "            reduction='mean',\n",
    "            get_preds=True\n",
    "        )\n",
    "        action_masked = action.view(-1)[still_alive.view(-1)]\n",
    "\n",
    "        test_metrics['policy_loss'] += policy_loss.detach().cpu().item()\n",
    "        test_metrics['value_loss'] += value_loss.detach().cpu().item()\n",
    "        test_metrics['entropy_loss'] += entropy_loss.detach().cpu().item()\n",
    "        test_metrics['combined_loss'] += combined_loss.detach().cpu().item()\n",
    "        test_metrics['policy_accuracy'] += preds.eq(action_masked).sum().cpu().item()\n",
    "        n_test_samples += still_alive.sum().cpu().item()\n",
    "\n",
    "    for key, metric in test_metrics.items():\n",
    "        test_metrics[key] = metric / n_test_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numeric-brown",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train metrics\n",
    "print(test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neither-great",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train metrics\n",
    "print(test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appreciated-blend",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test metrics\n",
    "print(test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "middle-volunteer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train metrics\n",
    "print(test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatty-hampton",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test metrics\n",
    "print(test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "postal-communist",
   "metadata": {},
   "outputs": [],
   "source": [
    "#env = kaggle_make('hungry_geese', debug=True)\n",
    "#env.reset(num_agents=4);\n",
    "replay_dict = read_json('/home/isaiah/Downloads/19528131.json')\n",
    "env = kaggle_make(\n",
    "    'hungry_geese',\n",
    "    configuration=replay_dict['configuration'],\n",
    "    steps=replay_dict['steps'],\n",
    "    info=replay_dict['info']\n",
    ")\n",
    "env.render(mode='ipython', height=700, width=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coated-prayer",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_tree = BasicMCTS(\n",
    "    action_mask_func=action_mask_func,\n",
    "    actor_critic_func=actor_critic_func,\n",
    "    terminal_value_func=terminal_value_func,\n",
    "    c_puct = 1.,\n",
    "    include_food=False\n",
    ")\n",
    "step_idx = 120\n",
    "state = env.steps[step_idx][0]\n",
    "state.update(env.steps[step_idx][0]['observation'])\n",
    "obs = Observation(state)\n",
    "light_env = make_from_state(\n",
    "    obs,\n",
    "    [Action[agent['action']] for agent in env.steps[-1]],\n",
    "    env.configuration\n",
    ")\n",
    "print(light_env.render_ansi())\n",
    "\n",
    "root_node = search_tree.run_mcts(\n",
    "    env=light_env,\n",
    "    n_iter=10000,\n",
    "    max_time=0.5\n",
    ")\n",
    "print(root_node.initial_policies)\n",
    "print(root_node.initial_values)\n",
    "print(root_node.q_vals)\n",
    "print(root_node.n_visits / root_node.n_visits.sum(axis=1, keepdims=True))\n",
    "print(root_node.n_visits.sum(axis=1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "answering-morris",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "search_tree = BasicMCTS(\n",
    "    action_mask_func=action_mask_func,\n",
    "    actor_critic_func=actor_critic_func,\n",
    "    terminal_value_func=terminal_value_func,\n",
    "    c_puct = np.sqrt(2.),\n",
    "    include_food=False\n",
    ")\n",
    "while not env.done:\n",
    "    state = env.steps[-1][0]\n",
    "    state.update(env.steps[-1][0]['observation'])\n",
    "    obs = Observation(state)\n",
    "    light_env = make_from_state(\n",
    "        obs,\n",
    "        [Action[agent['action']] for agent in env.steps[-1]],\n",
    "        env.configuration\n",
    "    )\n",
    "    print(light_env.render_ansi())\n",
    "    \n",
    "    csr = light_env.canonical_string_repr(include_food=search_tree.include_food)\n",
    "    for key in list(search_tree.nodes.keys()):\n",
    "        if key.startswith(f'S: {obs.step - 1}') or (key.startswith(f'S: {obs.step}') and key != csr):\n",
    "            del search_tree.nodes[key]\n",
    "    root_node = search_tree.run_mcts(\n",
    "        env=light_env,\n",
    "        n_iter=10000,\n",
    "        max_time=0.3\n",
    "    )\n",
    "    print(root_node.n_visits)\n",
    "    print(int(root_node.n_visits.sum() / 4))\n",
    "    actions = root_node.get_improved_actions(0.)\n",
    "    env.step([tuple(Action)[a].name for a in actions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loose-multiple",
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_critic_func(env.steps[-12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "victorian-network",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.render(mode='ipython', height=700, width=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "significant-lecture",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(root_node.n_visits)\n",
    "print(int(root_node.n_visits.sum() / 4))\n",
    "root_node.q_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dress-mongolia",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as colors\n",
    "for s, a, r, hl, alive in ag_dataloader:\n",
    "    square = np.ceil(np.sqrt(s.shape[1])).astype(np.int)\n",
    "    fig, axs = plt.subplots(square, square, figsize=(20,10))\n",
    "    ix = 0\n",
    "    for i in range(square):\n",
    "        for j in range(square):\n",
    "            ax = axs[i, j]\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "            eps = 1e-2\n",
    "            if ix < s.shape[1]:\n",
    "                pcm = ax.imshow(s[0, ix, :, :] + eps, norm=colors.LogNorm(vmin=eps, vmax=1.), cmap='gray')\n",
    "                ix += 1\n",
    "    fig.colorbar(pcm, ax = axs)\n",
    "    plt.show()\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
