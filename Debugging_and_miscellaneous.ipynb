{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "demonstrated-psychiatry",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaggle_environments.envs.hungry_geese.hungry_geese import Action, Configuration, Observation, histogram, translate, row_col\n",
    "from kaggle_environments import make as kaggle_make\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import tqdm\n",
    "\n",
    "from hungry_geese.nns import models, conv_blocks\n",
    "from hungry_geese.env.torch_env import TorchEnv\n",
    "from hungry_geese.mcts.torch_mcts import TorchMCTS\n",
    "import hungry_geese.env.goose_env as ge\n",
    "from hungry_geese.mcts.utils import torch_actor_critic_factory, torch_terminal_value_func\n",
    "#device = torch.device('cuda:0')\n",
    "device = torch.device('cpu')\n",
    "\n",
    "config = Configuration(kaggle_make('hungry_geese', debug=False).configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "radical-march",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_type = ge.ObsType.COMBINED_GRADIENT_OBS_LARGE\n",
    "n_channels = 64\n",
    "activation = nn.ReLU\n",
    "normalize = False\n",
    "use_mhsa = False\n",
    "model_kwargs = dict(\n",
    "    block_class=conv_blocks.BasicConvolutionalBlock,\n",
    "    conv_block_kwargs=[\n",
    "        dict(\n",
    "            in_channels=obs_type.get_obs_spec()[-3],\n",
    "            out_channels=n_channels,\n",
    "            kernel_size=3,\n",
    "            activation=activation,\n",
    "            normalize=normalize,\n",
    "            use_mhsa=False\n",
    "        ),\n",
    "        dict(\n",
    "            in_channels=n_channels,\n",
    "            out_channels=n_channels,\n",
    "            kernel_size=3,\n",
    "            activation=activation,\n",
    "            normalize=normalize,\n",
    "            use_mhsa=False\n",
    "        ),\n",
    "        dict(\n",
    "            in_channels=n_channels,\n",
    "            out_channels=n_channels,\n",
    "            kernel_size=3,\n",
    "            activation=activation,\n",
    "            normalize=normalize,\n",
    "            use_mhsa=False\n",
    "        ),\n",
    "        dict(\n",
    "            in_channels=n_channels,\n",
    "            out_channels=n_channels,\n",
    "            kernel_size=3,\n",
    "            activation=activation,\n",
    "            normalize=normalize,\n",
    "            use_mhsa=False\n",
    "        ),\n",
    "        dict(\n",
    "            in_channels=n_channels,\n",
    "            out_channels=n_channels,\n",
    "            kernel_size=3,\n",
    "            activation=activation,\n",
    "            normalize=normalize,\n",
    "            use_mhsa=use_mhsa,\n",
    "            mhsa_heads=4,\n",
    "        ),\n",
    "    ],\n",
    "    squeeze_excitation=True,\n",
    "    cross_normalize_value=True,\n",
    "    use_separate_action_value_heads=True,\n",
    "    # **ge.RewardType.RANK_ON_DEATH.get_recommended_value_activation_scale_shift_dict()\n",
    ")\n",
    "model = models.FullConvActorCriticNetwork(**model_kwargs)\n",
    "model.load_state_dict(torch.load(Path.home() / 'goose_agent/cp.pt'))\n",
    "model.to(device)\n",
    "\n",
    "env_kwargs = dict(\n",
    "    config=config,\n",
    "    n_envs=2,\n",
    "    obs_type=obs_type,\n",
    "    device=device\n",
    ")\n",
    "env = TorchEnv(**env_kwargs)\n",
    "env_copy = TorchEnv(**env_kwargs)\n",
    "mcts = TorchMCTS(\n",
    "    torch_actor_critic_factory(model),\n",
    "    torch_terminal_value_func,\n",
    "    100,\n",
    "    add_noise=True,\n",
    "    device=device,\n",
    "    n_envs=env.n_envs,\n",
    "    max_size=250\n",
    ")\n",
    "tree = mcts.tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "scheduled-turkey",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 101/101 [00:01<00:00, 66.58it/s]\n",
      "100%|██████████| 101/101 [00:01<00:00, 70.23it/s]\n",
      "100%|██████████| 101/101 [00:01<00:00, 81.55it/s]\n",
      "100%|██████████| 101/101 [00:01<00:00, 86.26it/s]\n",
      "100%|██████████| 101/101 [00:01<00:00, 79.66it/s]\n",
      "100%|██████████| 101/101 [00:01<00:00, 76.52it/s]\n",
      "100%|██████████| 101/101 [00:01<00:00, 75.47it/s]\n",
      "100%|██████████| 101/101 [00:01<00:00, 87.01it/s]\n",
      "100%|██████████| 101/101 [00:01<00:00, 83.42it/s]\n",
      "100%|██████████| 101/101 [00:01<00:00, 81.19it/s]\n",
      "100%|██████████| 101/101 [00:01<00:00, 80.70it/s]\n",
      "100%|██████████| 101/101 [00:01<00:00, 74.81it/s]\n",
      "100%|██████████| 101/101 [00:01<00:00, 69.78it/s]\n",
      "100%|██████████| 101/101 [00:01<00:00, 74.99it/s]\n",
      "100%|██████████| 101/101 [00:01<00:00, 84.26it/s]\n",
      " 20%|█▉        | 20/101 [00:00<00:01, 80.04it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-4ba8c032b26e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdones\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmcts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmcts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_mcts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv_copy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_progress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mpolicies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmcts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_improved_policies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mpolicy_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Windows/Users/isaia/Documents/GitHub/Kaggle/Hungry_Geese/hungry_geese/mcts/torch_mcts.py\u001b[0m in \u001b[0;36mrun_mcts\u001b[0;34m(self, env, env_placeholder, n_iter, show_progress)\u001b[0m\n\u001b[1;32m    309\u001b[0m             self._expand_and_backpropagate(\n\u001b[1;32m    310\u001b[0m                 \u001b[0menv_placeholder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_noise\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_at_root\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_at_leaf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m             )\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Windows/Users/isaia/Documents/GitHub/Kaggle/Hungry_Geese/hungry_geese/mcts/torch_mcts.py\u001b[0m in \u001b[0;36m_expand_and_backpropagate\u001b[0;34m(self, env_copy, add_policy_noise)\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0menv_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_locs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m             \u001b[0menv_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malive\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m             \u001b[0menv_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m         )\n\u001b[1;32m    271\u001b[0m         values = torch.where(\n",
      "\u001b[0;32m/Windows/Users/isaia/Documents/GitHub/Kaggle/Hungry_Geese/hungry_geese/mcts/utils.py\u001b[0m in \u001b[0;36mtorch_actor_critic_func\u001b[0;34m(obs, head_locs, still_alive, rewards)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mn_geese\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhead_locs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m             \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_locs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstill_alive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m             \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;31m# Score the dead geese\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pt17/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Windows/Users/isaia/Documents/GitHub/Kaggle/Hungry_Geese/hungry_geese/nns/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, states, head_locs, still_alive)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \"\"\"\n\u001b[1;32m    138\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_geese\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhead_locs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m         \u001b[0mbase_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbase_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             raise RuntimeError(f'Fully convolutional networks must use padding so that the input and output sizes match'\n",
      "\u001b[0;32m~/miniconda3/envs/pt17/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Windows/Users/isaia/Documents/GitHub/Kaggle/Hungry_Geese/hungry_geese/nns/conv_blocks.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    121\u001b[0m         ):\n\u001b[1;32m    122\u001b[0m             \u001b[0midentity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pt17/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Windows/Users/isaia/Documents/GitHub/Kaggle/Hungry_Geese/hungry_geese/nns/conv_blocks.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pt17/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pt17/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pt17/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pt17/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pt17/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_mode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'zeros'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             return F.conv2d(F.pad(input, self._reversed_padding_repeated_twice, mode=self.padding_mode),\n\u001b[0m\u001b[1;32m    417\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m                             _pair(0), self.dilation, self.groups)\n",
      "\u001b[0;32m~/miniconda3/envs/pt17/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_pad\u001b[0;34m(input, pad, mode, value)\u001b[0m\n\u001b[1;32m   3572\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplication_pad2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3573\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'circular'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3574\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_pad_circular\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3575\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3576\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pt17/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_pad_circular\u001b[0;34m(input, padding)\u001b[0m\n\u001b[1;32m   4017\u001b[0m             \u001b[0mo1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4018\u001b[0m             \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mo1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4019\u001b[0;31m                 \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4020\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4021\u001b[0m     \u001b[0;31m# Pad third dimension (width)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while not env.dones.any():\n",
    "    mcts.reset()\n",
    "    mcts.run_mcts(env, env_copy, show_progress=True)\n",
    "    policies = mcts.tree.get_improved_policies()\n",
    "    policy_max = policies.max(dim=-1, keepdim=True).values\n",
    "    actions = torch.multinomial(\n",
    "        (policies == policy_max).view(-1, 4).to(torch.float32),\n",
    "        1\n",
    "    ).view(-1, env.n_geese)\n",
    "    env.step(torch.where(\n",
    "        env.alive,\n",
    "        actions,\n",
    "        torch.zeros_like(actions)\n",
    "    ))\n",
    "    obs_dict = env.generate_obs_dicts()\n",
    "    for env_idx in range(env.n_envs):\n",
    "        assert np.allclose(\n",
    "            env.obs[env_idx].cpu().numpy(),\n",
    "            ge.create_obs_tensor(obs_dict[env_idx], env.obs_type)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "surprising-mouth",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:02<00:00,  8.24it/s]\n"
     ]
    }
   ],
   "source": [
    "mcts.reset()\n",
    "env.reset()\n",
    "profiling_enabled = False\n",
    "n_mcts_iter = 20\n",
    "with torch.autograd.profiler.profile(enabled=profiling_enabled, use_cuda=True) as prof:\n",
    "    mcts.run_mcts(env, env_copy, n_mcts_iter, show_progress=True)\n",
    "#if profiling_enabled:\n",
    "#    prof.export_chrome_trace(f'trace_{str(device).split(\":\")[0]}_{env.n_envs}_envs_{n_mcts_iter}_iter.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "german-rolling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0\n",
      "Lengths: [1, 1, 1, 1]\n",
      "Rewards: [0, 0, 0, 0]\n",
      "\n",
      "_ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ C _\n",
      "_ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ * A _ _\n",
      "D _ _ _ _ _ _ _ _ _ _\n",
      "_ B * _ _ _ _ _ _ _ _\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.2000, 0.0000, 0.0500, 0.7500],\n",
       "        [0.0500, 0.9000, 0.0500, 0.0000],\n",
       "        [0.2000, 0.2000, 0.0500, 0.5500],\n",
       "        [0.6500, 0.0500, 0.0500, 0.2500]], device='cuda:0')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_idx = 0\n",
    "print(env.render_env(env_idx, include_info=True))\n",
    "mcts.tree.get_improved_policies(1.)[env_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "square-darwin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'action': 'NORTH',\n",
       "  'reward': 0,\n",
       "  'info': {},\n",
       "  'observation': {'index': 0,\n",
       "   'step': 0,\n",
       "   'geese': [[52], [67], [31], [55]],\n",
       "   'food': [51, 68]},\n",
       "  'status': 'ACTIVE'},\n",
       " {'action': 'NORTH',\n",
       "  'reward': 0,\n",
       "  'info': {},\n",
       "  'observation': {'index': 1},\n",
       "  'status': 'ACTIVE'},\n",
       " {'action': 'NORTH',\n",
       "  'reward': 0,\n",
       "  'info': {},\n",
       "  'observation': {'index': 2},\n",
       "  'status': 'ACTIVE'},\n",
       " {'action': 'NORTH',\n",
       "  'reward': 0,\n",
       "  'info': {},\n",
       "  'observation': {'index': 3},\n",
       "  'status': 'ACTIVE'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_dict = env.generate_obs_dicts()\n",
    "obs_dict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "vertical-holly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "825 ms ± 1.82 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit env.generate_obs_dicts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "alternative-inspector",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.2 s ± 526 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'obs_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-5ae5203f05dc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'timeit'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'obs_dict = env.generate_obs_dicts()'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mobs_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'obs_dict' is not defined"
     ]
    }
   ],
   "source": [
    "%timeit obs_dict = env.generate_obs_dicts()\n",
    "obs_dict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "closed-tissue",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                         Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-----------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "           mcts_backpropagate         0.16%      21.880ms        10.99%        1.473s      14.586ms       8.015ms         0.01%       51.872s     513.587ms           101  \n",
      "                   aten::item         0.60%      79.913ms         6.04%     810.280ms      85.880us       50.862s        79.20%       51.649s       5.474ms          9435  \n",
      "             aten::is_nonzero         0.08%      10.221ms         1.49%     200.264ms      92.801us      13.207ms         0.02%       50.964s      23.616ms          2158  \n",
      "                  mcts_expand         2.38%     318.850ms        75.57%       10.134s     100.333ms     253.241ms         0.39%        9.870s      97.721ms           101  \n",
      "                     env_step         9.69%        1.299s        63.45%        8.509s      26.101ms     239.937ms         0.37%        8.109s      24.873ms           326  \n",
      "                aten::nonzero        21.27%        2.852s        25.16%        3.375s     128.401us        3.680s         5.73%        3.866s     147.081us         26282  \n",
      "                  aten::index         7.60%        1.019s        32.40%        4.345s     125.539us     529.163ms         0.82%        3.744s     108.169us         34611  \n",
      "                    mcts_eval         3.22%     431.776ms        13.11%        1.757s      17.400ms     341.356ms         0.53%        2.457s      24.330ms           101  \n",
      "      aten::repeat_interleave         1.28%     171.374ms        12.59%        1.689s     410.457us  -235950.765us        -0.37%        1.234s     299.877us          4114  \n",
      "             aten::index_put_         1.05%     140.735ms        11.23%        1.506s     110.966us      94.064ms         0.15%        1.164s      85.773us         13568  \n",
      "       aten::_index_put_impl_         2.44%     327.676ms        10.18%        1.365s     100.594us     169.585ms         0.26%        1.070s      78.840us         13568  \n",
      "                     aten::to         2.05%     275.369ms         4.29%     575.249ms       6.150us     383.558ms         0.60%        1.031s      11.024us         93538  \n",
      "                update_values         1.12%     150.414ms         7.60%        1.019s       3.125ms   -7144.570us        -0.01%     844.162ms       2.589ms           326  \n",
      "                  aten::copy_         3.17%     425.483ms         3.17%     425.521ms      16.795us     803.937ms         1.25%     803.937ms      31.731us         25336  \n",
      "    aten::_local_scalar_dense         5.45%     730.366ms         5.45%     730.366ms      77.410us     787.355ms         1.23%     787.355ms      83.450us          9435  \n",
      "                    aten::add         1.16%     155.587ms         1.28%     171.267ms      32.778us     511.731ms         0.80%     511.731ms      97.939us          5225  \n",
      "                    aten::sum         1.11%     148.969ms         1.62%     216.801ms      42.965us     417.327ms         0.65%     439.803ms      87.159us          5046  \n",
      "                  aten::where         0.56%      75.342ms         1.34%     180.284ms      48.476us     282.369ms         0.44%     321.700ms      86.502us          3719  \n",
      "                     aten::eq         0.80%     106.721ms         1.29%     172.908ms      29.936us     293.095ms         0.46%     314.364ms      54.426us          5776  \n",
      "            aten::multinomial         0.46%      62.009ms         2.85%     382.681ms     586.934us   -3945.781us        -0.01%     280.074ms     429.561us           652  \n",
      "                    aten::mul         0.69%      92.556ms         0.76%     101.961ms      34.645us     258.510ms         0.40%     258.510ms      87.839us          2943  \n",
      "              aten::remainder         0.65%      87.829ms         0.77%     103.908ms      45.534us     253.951ms         0.40%     258.409ms     113.238us          2282  \n",
      "                aten::__and__         0.54%      72.799ms         1.29%     172.646ms      48.145us     204.873ms         0.32%     247.304ms      68.964us          3586  \n",
      "                   aten::rsub         0.36%      48.399ms         0.40%      53.001ms      37.723us     240.470ms         0.37%     240.470ms     171.153us          1405  \n",
      "                    aten::all         0.65%      86.815ms         0.81%     108.323ms      27.854us     237.291ms         0.37%     238.438ms      61.311us          3889  \n",
      "                     aten::gt         0.60%      81.064ms         0.89%     118.829ms      30.737us     215.722ms         0.34%     225.619ms      58.360us          3866  \n",
      "                 aten::arange         0.30%      40.819ms         0.46%      61.995ms      24.640us     205.980ms         0.32%     217.937ms      86.620us          2516  \n",
      "                    aten::div         0.44%      58.679ms         0.48%      64.544ms      33.391us     206.913ms         0.32%     206.913ms     107.043us          1933  \n",
      "                go_to_parents         0.42%      56.035ms         2.61%     350.517ms       1.075ms  -170846.172us        -0.27%     200.816ms     615.999us           326  \n",
      "             aten::contiguous         1.39%     186.067ms         2.42%     324.922ms       6.110us     115.154ms         0.18%     192.782ms       3.625us         53177  \n",
      "                   aten::add_         0.51%      68.979ms         0.51%      68.979ms      23.438us     184.513ms         0.29%     184.513ms      62.696us          2943  \n",
      "                    aten::sub         0.33%      44.873ms         0.37%      48.988ms      34.091us     182.413ms         0.28%     182.413ms     126.940us          1437  \n",
      "                 aten::conv2d         0.20%      27.034ms         1.45%     194.898ms     175.425us      24.382ms         0.04%     179.797ms     161.834us          1111  \n",
      "                  aten::relu_         0.28%      37.515ms         0.39%      51.942ms      34.285us     153.301ms         0.24%     162.542ms     107.289us          1515  \n",
      "                aten::reshape         2.12%     284.101ms         3.64%     487.919ms       5.266us     161.072ms         0.25%     161.072ms       1.738us         92657  \n",
      "             aten::zeros_like         0.20%      26.288ms         0.37%      49.981ms      43.199us     151.943ms         0.24%     160.953ms     139.113us          1157  \n",
      "            aten::convolution         0.05%       6.557ms         1.25%     167.864ms     151.093us       3.766ms         0.01%     155.415ms     139.888us          1111  \n",
      "           aten::_convolution         0.16%      21.115ms         1.20%     161.307ms     145.190us       9.525ms         0.01%     151.649ms     136.498us          1111  \n",
      "                     aten::lt         0.39%      52.160ms         0.61%      81.847ms      25.106us     133.641ms         0.21%     141.187ms      43.309us          3260  \n",
      "                  aten::zeros         0.24%      32.637ms         0.47%      63.638ms      27.231us     118.275ms         0.18%     138.369ms      59.208us          2337  \n",
      "                   aten::set_         1.70%     227.778ms         1.70%     227.778ms       8.667us     135.549ms         0.21%     135.549ms       5.157us         26282  \n",
      "                 aten::matmul         0.21%      28.557ms         0.48%      64.626ms      53.322us     117.395ms         0.18%     130.876ms     107.984us          1212  \n",
      "                   aten::sub_         0.22%      29.993ms         0.22%      29.993ms      23.001us     130.008ms         0.20%     130.008ms      99.699us          1304  \n",
      "      aten::cudnn_convolution         0.72%      96.171ms         0.83%     111.450ms     100.315us     117.111ms         0.18%     120.920ms     108.839us          1111  \n",
      "                     aten::ge         0.59%      79.356ms         1.02%     137.188ms      20.409us     104.999ms         0.16%     120.479ms      17.923us          6722  \n",
      "                 aten::gather         0.23%      30.286ms         0.27%      36.417ms      45.070us     114.776ms         0.18%     114.776ms     142.049us           808  \n",
      "                 aten::select         1.57%     210.972ms         1.84%     246.657ms       5.795us      99.439ms         0.15%      99.439ms       2.336us         42563  \n",
      "                 aten::cumsum         0.16%      21.384ms         0.85%     114.453ms      55.533us      48.050ms         0.07%      93.041ms      45.143us          2061  \n",
      "            aten::bitwise_and         0.66%      88.243ms         1.37%     184.329ms      21.747us      47.484ms         0.07%      80.488ms       9.496us          8476  \n",
      "                    aten::any         0.08%      11.276ms         0.10%      12.976ms      39.804us      72.492ms         0.11%      72.492ms     222.367us           326  \n",
      "    aten::adaptive_avg_pool2d         0.08%      11.130ms         0.17%      22.647ms      44.845us      61.086ms         0.10%      69.815ms     138.247us           505  \n",
      "                    aten::max         0.21%      27.872ms         0.26%      35.263ms      32.682us      64.941ms         0.10%      66.072ms      61.234us          1079  \n",
      "                 aten::clamp_         0.06%       8.240ms         0.10%      13.670ms      41.933us      58.657ms         0.09%      61.483ms     188.598us           326  \n",
      "            aten::bitwise_not         0.42%      55.774ms         0.86%     114.868ms      23.122us      33.417ms         0.05%      58.349ms      11.745us          4968  \n",
      "                aten::sigmoid         0.14%      18.652ms         0.21%      28.455ms      28.174us      55.433ms         0.09%      57.937ms      57.364us          1010  \n",
      "                 aten::__or__         0.05%       6.351ms         0.12%      15.997ms      49.071us      53.406ms         0.08%      57.048ms     174.993us           326  \n",
      "                     aten::le         0.11%      15.231ms         0.16%      21.784ms      33.411us      52.036ms         0.08%      53.457ms      81.989us           652  \n",
      "                aten::minimum         0.09%      11.415ms         0.09%      12.514ms      38.387us      45.954ms         0.07%      45.954ms     140.963us           326  \n",
      "               aten::scatter_         0.12%      15.548ms         0.12%      16.645ms      41.202us      45.674ms         0.07%      45.674ms     113.055us           404  \n",
      "                     aten::ne         0.13%      17.125ms         0.19%      24.872ms      30.783us      43.198ms         0.07%      45.300ms      56.064us           808  \n",
      "          aten::nonzero_numpy         0.01%       1.588ms         0.35%      46.331ms     229.361us       1.043ms         0.00%      44.289ms     219.254us           202  \n",
      "          aten::scalar_tensor         0.27%      36.060ms         0.70%      93.535ms      17.932us      18.133ms         0.03%      43.134ms       8.270us          5216  \n",
      "                  aten::fill_         0.51%      68.351ms         0.51%      68.351ms       7.261us      41.445ms         0.06%      41.445ms       4.403us          9413  \n",
      "                aten::_cumsum         0.33%      44.368ms         0.65%      87.832ms      42.616us      23.004ms         0.04%      41.168ms      19.975us          2061  \n",
      "                    aten::cat         0.12%      16.437ms         0.24%      32.808ms      54.138us      36.431ms         0.06%      39.628ms      65.392us           606  \n",
      "                   aten::sqrt         0.09%      12.233ms         0.14%      18.937ms      29.044us      36.746ms         0.06%      38.368ms      58.846us           652  \n",
      "                  aten::zero_         0.14%      18.233ms         0.30%      39.975ms      11.441us      15.544ms         0.02%      29.105ms       8.330us          3494  \n",
      "               aten::_s_where         0.42%      56.024ms         0.49%      65.928ms      19.431us      28.078ms         0.04%      28.078ms       8.275us          3393  \n",
      "                aten::softmax         0.03%       4.361ms         0.07%       9.829ms      48.659us      23.126ms         0.04%      25.545ms     126.461us           202  \n",
      "                   aten::mul_         0.07%       9.319ms         0.07%       9.319ms      28.587us      18.900ms         0.03%      18.900ms      57.975us           326  \n",
      "           aten::index_select         0.30%      40.563ms         0.35%      46.763ms      22.734us      17.781ms         0.03%      18.101ms       8.800us          2057  \n",
      "                 aten::repeat         0.14%      18.311ms         0.24%      32.546ms      76.219us       9.828ms         0.02%      16.318ms      38.215us           427  \n",
      "                     aten::mm         0.21%      28.348ms         0.25%      33.871ms      27.946us      13.143ms         0.02%      13.143ms      10.844us          1212  \n",
      "                   aten::topk         0.07%       9.674ms         0.07%       9.674ms      14.837us      11.620ms         0.02%      11.620ms      17.822us           652  \n",
      "               aten::uniform_         0.06%       7.708ms         0.06%       7.708ms      11.823us      10.134ms         0.02%      10.134ms      15.543us           652  \n",
      "             aten::threshold_         0.11%      14.427ms         0.11%      14.427ms       9.523us       9.241ms         0.01%       9.241ms       6.100us          1515  \n",
      "                  aten::clone         0.04%       5.812ms         0.07%       9.516ms      47.110us       8.308ms         0.01%       9.172ms      45.406us           202  \n",
      "                   aten::ones         0.04%       4.900ms         0.05%       7.138ms      35.336us       8.009ms         0.01%       8.874ms      43.930us           202  \n",
      "                   aten::mean         0.07%       9.573ms         0.09%      11.517ms      22.806us       8.729ms         0.01%       8.729ms      17.284us           505  \n",
      "              aten::ones_like         0.03%       4.398ms         0.06%       7.388ms      36.576us       6.569ms         0.01%       7.438ms      36.824us           202  \n",
      "                aten::argsort         0.03%       4.588ms         0.08%      11.059ms      54.749us       3.803ms         0.01%       7.206ms      35.672us           202  \n",
      "                    aten::min         0.09%      12.072ms         0.12%      16.184ms      24.821us       5.797ms         0.01%       6.916ms      10.607us           652  \n",
      "             aten::bitwise_or         0.06%       7.667ms         0.12%      15.942ms      24.452us       3.641ms         0.01%       6.175ms       9.471us           652  \n",
      "                  aten::alias         0.09%      11.457ms         0.09%      11.457ms       7.973us       6.152ms         0.01%       6.152ms       4.281us          1437  \n",
      "                   aten::log_         0.03%       3.682ms         0.07%       8.745ms      13.413us       2.252ms         0.00%       5.286ms       8.107us           652  \n",
      "                    aten::neg         0.03%       3.740ms         0.04%       5.642ms      27.932us       4.132ms         0.01%       4.577ms      22.656us           202  \n",
      "                   aten::div_         0.04%       4.812ms         0.04%       4.812ms       7.381us       3.862ms         0.01%       3.862ms       5.924us           652  \n",
      "           aten::masked_fill_         0.03%       3.583ms         0.03%       3.583ms      35.476us       3.850ms         0.01%       3.850ms      38.116us           101  \n",
      "                aten::flatten         0.04%       5.091ms         0.04%       5.091ms       2.475us       3.846ms         0.01%       3.846ms       1.870us          2057  \n",
      "               aten::linspace         0.02%       2.922ms         0.03%       3.998ms      19.793us       3.273ms         0.01%       3.790ms      18.765us           202  \n",
      "                   aten::sort         0.05%       6.471ms         0.05%       6.471ms      32.036us       3.403ms         0.01%       3.403ms      16.844us           202  \n",
      "                   aten::_cat         0.09%      11.636ms         0.12%      16.370ms      27.014us       3.196ms         0.00%       3.196ms       5.275us           606  \n",
      "              aten::expand_as         0.03%       3.505ms         0.07%       8.973ms       7.913us       3.099ms         0.00%       3.099ms       2.732us          1134  \n",
      "                    aten::log         0.04%       5.063ms         0.04%       5.063ms       7.765us       3.034ms         0.00%       3.034ms       4.654us           652  \n",
      "                  aten::clamp         0.02%       2.156ms         0.04%       5.430ms      16.658us       1.111ms         0.00%       2.826ms       8.667us           326  \n",
      "                 aten::unbind         0.02%       3.034ms         0.04%       5.061ms      25.054us       1.744ms         0.00%       2.441ms      12.085us           202  \n",
      "               aten::_softmax         0.03%       3.821ms         0.04%       5.468ms      27.068us       2.085ms         0.00%       2.419ms      11.978us           202  \n",
      "              aten::clamp_min         0.02%       3.275ms         0.02%       3.275ms      10.045us       1.715ms         0.00%       1.715ms       5.260us           326  \n",
      "                 aten::unfold         0.02%       2.309ms         0.02%       2.951ms       6.911us     884.955us         0.00%     884.955us       2.072us           427  \n",
      "                  aten::slice         1.01%     134.951ms         1.27%     169.793ms       4.197us       0.000us         0.00%       0.000us       0.000us         40456  \n",
      "-----------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 13.410s\n",
      "CUDA time total: 64.221s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_level_events_only = False\n",
    "if torch.device == torch.device('cpu'):\n",
    "    print(prof.key_averages().table(sort_by=\"cpu_time_total\", top_level_events_only=top_level_events_only))\n",
    "else:\n",
    "    print(prof.key_averages().table(sort_by=\"cuda_time_total\", top_level_events_only=top_level_events_only))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "democratic-smile",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = \n",
    "\n",
    "moves = torch.zeros((test.n_envs, test.n_geese), dtype=torch.int64, device=device) + 1\n",
    "update_mask = torch.ones((test.n_envs,), dtype=torch.bool, device=device)\n",
    "update_mask[-1] = False\n",
    "\n",
    "profiling_enabled = False\n",
    "with torch.autograd.profiler.profile(enabled=profiling_enabled, use_cuda=True) as prof:\n",
    "    test.reset()\n",
    "    for i in tqdm.trange(40):\n",
    "        test.step(moves, update_mask)\n",
    "print(test.render_env(0, include_info=True))\n",
    "if profiling_enabled:\n",
    "    prof.export_chrome_trace(f'trace_{str(device).split(\":\")[0]}_{test.n_envs}_envs.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparable-bailey",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test.render_env(-1, include_info=True))\n",
    "test.obs[-1][test.obs_channel_idxs['steps_since_starvation']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identical-bibliography",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_level_events_only = True\n",
    "if torch.device == torch.device('cpu'):\n",
    "    print(prof.key_averages().table(sort_by=\"cpu_time_total\"))\n",
    "else:\n",
    "    print(prof.key_averages().table(sort_by=\"cuda_time_total\", top_level_events_only=top_level_events_only))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "central-thong",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_idx = 1\n",
    "test.geese_tensor[env_idx], test.lengths[env_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adolescent-ireland",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.dones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooperative-grass",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.geese[sc].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focal-federal",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.arange(8).view(2, 4) % torch.tensor([2, 3]).view(2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "natural-progress",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "test.geese[torch.arange(test.n_envs)[test.dones], :, 0] = 1\n",
    "test.geese.sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "creative-trouble",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_rows = 7\n",
    "n_cols = 11\n",
    "\n",
    "head_locs = torch.multinomial(\n",
    "    torch.ones((3, n_rows * n_cols)),\n",
    "    4\n",
    ")\n",
    "loc_to_row_column = torch.tensor(\n",
    "    [row_col(i, n_cols) for i in range(n_rows * n_cols)],\n",
    ").view(n_rows * n_cols, 2)\n",
    "loc_to_row_column[head_locs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immune-training",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kaggle_environments\n",
    "from kaggle_environments.envs.hungry_geese.hungry_geese import Action, Configuration, Observation\n",
    "\n",
    "from hungry_geese.utils import read_json\n",
    "from hungry_geese.env.lightweight_env import make_from_state\n",
    "import main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "golden-semiconductor",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_from_state(Observation(env.steps[-2][0]['observation']), [Action.NORTH] * 4).done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plain-subscription",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(env.steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infectious-senior",
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_dict = read_json('/home/isaiah/Downloads/19998794.json')\n",
    "env = kaggle_environments.make(\n",
    "    'hungry_geese',\n",
    "    configuration=replay_dict['configuration'],\n",
    "    steps=replay_dict['steps'],\n",
    "    info=replay_dict['info']\n",
    ")\n",
    "\n",
    "conf = env.configuration\n",
    "env.steps[119][0]['observation']['step'] = 0\n",
    "\n",
    "main.AGENT = None\n",
    "main.call_agent(env.steps[119][0]['observation'], conf)\n",
    "main.call_agent(env.steps[120][0]['observation'], conf)\n",
    "\"\"\"\n",
    "obs = Observation(Observation(env.steps[120][0]['observation']))\n",
    "main.AGENT.preprocess(obs, conf)\n",
    "light_env = make_from_state(obs, main.AGENT.last_actions)\n",
    "main.AGENT.search_tree.run_batch_mcts(light_env.lightweight_clone(), 1, n_iter=2)\n",
    "out = main.AGENT.search_tree.expand(light_env)\n",
    "out\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "harmful-general",
   "metadata": {},
   "outputs": [],
   "source": [
    "light_env.step_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaged-michigan",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(light_env.render_ansi())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fuzzy-nudist",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.render(mode='ipython', height=700, width=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continued-response",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_geese = 4\n",
    "values = torch.arange(8).view(2,4).to(torch.float)\n",
    "still_alive = torch.ones_like(values).to(torch.bool)\n",
    "still_alive[0,0:2] = False\n",
    "\n",
    "\n",
    "values.masked_fill_(~still_alive, float('-inf'))\n",
    "win_probs = torch.softmax(values, dim=-1)\n",
    "print(win_probs)\n",
    "remaining_rewards = torch.linspace(0., 1., n_geese, dtype=torch.float)\n",
    "remaining_rewards_min = remaining_rewards[-still_alive.sum(dim=-1)].unsqueeze(-1)\n",
    "remaining_rewards_var = 1. - remaining_rewards_min\n",
    "values = remaining_rewards_min + win_probs * remaining_rewards_var\n",
    "# TODO: This is a hacky solution - there should be a more elegant way to do this for any n_geese_remaining?\n",
    "print(values)\n",
    "values = torch.where(\n",
    "    still_alive.sum(dim=-1, keepdim=True) == 4,\n",
    "    values * 2.,\n",
    "    values\n",
    ")\n",
    "values = torch.where(\n",
    "    still_alive.sum(dim=-1, keepdim=True) == 3,\n",
    "    values * 1.2,\n",
    "    values\n",
    ")\n",
    "\n",
    "print(values)\n",
    "max_vals = values.max(dim=-1, keepdim=True)[0]\n",
    "values = torch.where(\n",
    "    max_vals > 1.,\n",
    "    torch.where(\n",
    "        values == max_vals,\n",
    "        values - (max_vals - 1.),\n",
    "        values + (max_vals - 1.) / still_alive.sum(dim=-1, keepdim=True)\n",
    "    ),\n",
    "    values\n",
    ")\n",
    "print(values)\n",
    "values * 2. - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approximate-sitting",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda')\n",
    "\n",
    "obs_type = ge.ObsType.COMBINED_GRADIENT_OBS\n",
    "n_channels = 128\n",
    "activation = nn.ReLU\n",
    "normalize = False\n",
    "model_kwargs = dict(\n",
    "    block_class=models.BasicConvolutionalBlock,\n",
    "    conv_block_kwargs=[\n",
    "        dict(\n",
    "            in_channels=obs_type.get_obs_spec()[-3],\n",
    "            out_channels=n_channels,\n",
    "            kernel_size=3,\n",
    "            activation=activation,\n",
    "            normalize=normalize\n",
    "        ),\n",
    "        dict(\n",
    "            in_channels=n_channels,\n",
    "            out_channels=n_channels,\n",
    "            kernel_size=3,\n",
    "            activation=activation,\n",
    "            normalize=normalize\n",
    "        ),\n",
    "        dict(\n",
    "            in_channels=n_channels,\n",
    "            out_channels=n_channels,\n",
    "            kernel_size=3,\n",
    "            activation=activation,\n",
    "            normalize=normalize\n",
    "        ),\n",
    "    ],\n",
    "    squeeze_excitation=True,\n",
    "    cross_normalize_value=True,\n",
    "    # **ge.RewardType.RANK_ON_DEATH.get_recommended_value_activation_scale_shift_dict()\n",
    ")\n",
    "model = models.FullConvActorCriticNetwork(**model_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "announced-elevation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import copy\n",
    "from kaggle_environments import make as kaggle_make\n",
    "from kaggle_environments.envs.hungry_geese.hungry_geese import Action, Configuration, Observation\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from scipy import special, stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.cuda import amp\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from hungry_geese import models\n",
    "from hungry_geese.utils import ActionMasking\n",
    "from hungry_geese.env import goose_env as ge\n",
    "from hungry_geese.env.lightweight_env import LightweightEnv, make_from_state\n",
    "from hungry_geese.mcts.basic_mcts import BasicMCTS\n",
    "from hungry_geese.training.alphagoose.alphagoose_data import AlphaGoosePretrainDataset, ToTensor\n",
    "from hungry_geese.utils import read_json\n",
    "\n",
    "%matplotlib inline\n",
    "DEVICE = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrong-investigator",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_type = ge.ObsType.COMBINED_GRADIENT_OBS\n",
    "n_channels = 64\n",
    "activation = nn.ReLU\n",
    "model_kwargs = dict(\n",
    "    block_class=models.BasicConvolutionalBlock,\n",
    "    conv_block_kwargs=[\n",
    "        dict(\n",
    "            in_channels=obs_type.get_obs_spec()[-3],\n",
    "            out_channels=n_channels,\n",
    "            kernel_size=3,\n",
    "            activation=activation,\n",
    "            normalize=False\n",
    "        ),\n",
    "        dict(\n",
    "            in_channels=n_channels,\n",
    "            out_channels=n_channels,\n",
    "            kernel_size=3,\n",
    "            activation=activation,\n",
    "            normalize=False\n",
    "        ),\n",
    "        dict(\n",
    "            in_channels=n_channels,\n",
    "            out_channels=n_channels,\n",
    "            kernel_size=3,\n",
    "            activation=activation,\n",
    "            normalize=False\n",
    "        ),\n",
    "        dict(\n",
    "            in_channels=n_channels,\n",
    "            out_channels=n_channels,\n",
    "            kernel_size=3,\n",
    "            activation=activation,\n",
    "            normalize=False\n",
    "        ),\n",
    "        dict(\n",
    "            in_channels=n_channels,\n",
    "            out_channels=n_channels,\n",
    "            kernel_size=3,\n",
    "            activation=activation,\n",
    "            normalize=False\n",
    "        ),\n",
    "    ],\n",
    "    squeeze_excitation=True,\n",
    "    cross_normalize_value=True,\n",
    "    # **ge.RewardType.RANK_ON_DEATH.get_recommended_value_activation_scale_shift_dict()\n",
    ")\n",
    "model = models.FullConvActorCriticNetwork(**model_kwargs)\n",
    "model.to(device=DEVICE)\n",
    "\n",
    "run_dir = Path('runs/supervised_pretraining/active/supervised_pretraining_combined_gradient_obs_rank_on_death_none_5_blocks_64_dims_v1/')\n",
    "with open(run_dir / '0070/cp.txt', 'r') as f:\n",
    "    serialized_string = f.readline()[2:-1].encode()\n",
    "state_dict_bytes = base64.b64decode(serialized_string)\n",
    "loaded_state_dicts = pickle.loads(state_dict_bytes)\n",
    "model.load_state_dict(loaded_state_dicts)\n",
    "\n",
    "def action_mask_func(state):\n",
    "    return ActionMasking.LETHAL.get_action_mask(state)\n",
    "    \n",
    "def terminal_value_func(state):\n",
    "    agent_rankings = stats.rankdata([agent['reward'] for agent in state], method='average') - 1.\n",
    "    ranks_rescaled = 2. * agent_rankings / (len(state) - 1.) - 1.\n",
    "    return ranks_rescaled\n",
    "    \n",
    "def actor_critic_func(state):\n",
    "    geese = state[0]['observation']['geese']\n",
    "    n_geese = len(geese)\n",
    "    \n",
    "    obs = ge.create_obs_tensor(state, obs_type)\n",
    "    head_locs = [goose[0] if len(goose) > 0 else -1 for goose in geese]\n",
    "    still_alive = [agent['status'] == 'ACTIVE' for agent in state]\n",
    "    with torch.no_grad():\n",
    "        logits, values = model(torch.from_numpy(obs),\n",
    "                               torch.tensor(head_locs).unsqueeze(0),\n",
    "                               torch.tensor(still_alive).unsqueeze(0))\n",
    "    \n",
    "    # Score the dead geese\n",
    "    dead_geese_mask = np.array([len(goose) for goose in geese]) == 0\n",
    "    agent_rankings = stats.rankdata([agent['reward'] for agent in state], method='average') - 1.\n",
    "    agent_rankings_rescaled = 2. * agent_rankings / (n_geese - 1.) - 1.\n",
    "    \n",
    "    logits = F.softmax(logits, -1)\n",
    "    final_values = np.where(\n",
    "        dead_geese_mask,\n",
    "        agent_rankings_rescaled,\n",
    "        values.squeeze(0).numpy()\n",
    "    )\n",
    "    \n",
    "    # Logits should be of shape (4, 4)\n",
    "    # Values should be of shape (4, 1)\n",
    "    return logits.squeeze(0).numpy().astype(np.float), final_values[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sudden-gabriel",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(run_dir / 'train_episodes.txt', 'r') as f:\n",
    "    train_episodes = [replay_name.rstrip() for replay_name in f.readlines()]\n",
    "    train_episodes = set(train_episodes)\n",
    "with open(run_dir / 'test_episodes.txt', 'r') as f:\n",
    "    test_episodes = [replay_name.rstrip() for replay_name in f.readlines()]\n",
    "    test_episodes = set(test_episodes)\n",
    "\n",
    "dataset_loc = Path('/home/isaiah/data/alphagoose_data_1000/')\n",
    "train_dataset = AlphaGoosePretrainDataset(\n",
    "    dataset_loc,\n",
    "    ge.ObsType.COMBINED_GRADIENT_OBS,\n",
    "    transform=ToTensor(),\n",
    "    include_episode=lambda x: x.stem in train_episodes\n",
    ")\n",
    "test_dataset = AlphaGoosePretrainDataset(\n",
    "    dataset_loc,\n",
    "    ge.ObsType.COMBINED_GRADIENT_OBS,\n",
    "    transform=ToTensor(),\n",
    "    include_episode=lambda x: x.stem in test_episodes\n",
    ")\n",
    "dataloader_kwargs = dict(\n",
    "    batch_size=512,\n",
    "    shuffle=True,\n",
    "    num_workers=6,\n",
    "    pin_memory=True\n",
    ")\n",
    "train_dataloader = DataLoader(train_dataset, **dataloader_kwargs)\n",
    "test_dataloader = DataLoader(test_dataset, **dataloader_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "allied-phenomenon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_losses(\n",
    "        state,\n",
    "        action,\n",
    "        result,\n",
    "        head_locs,\n",
    "        still_alive,\n",
    "        reduction='mean',\n",
    "        get_preds=False\n",
    "):\n",
    "    with amp.autocast():\n",
    "        logits, value = model(state, head_locs, still_alive)\n",
    "\n",
    "        logits_masked = logits.view(-1, 4)[still_alive.view(-1, 1).expand(-1, 4)].view(-1, 4)\n",
    "        action_masked = action.view(-1)[still_alive.view(-1)]\n",
    "        policy_loss = F.cross_entropy(logits_masked, action_masked, reduction=reduction)\n",
    "\n",
    "        value_masked = value.view(-1)[still_alive.view(-1)]\n",
    "        result_masked = result.view(-1)[still_alive.view(-1)]\n",
    "        value_loss = F.mse_loss(value_masked, result_masked, reduction=reduction)\n",
    "\n",
    "        probs_masked = F.softmax(logits_masked, dim=-1)\n",
    "        entropy_loss = torch.sum(probs_masked * torch.log(probs_masked), dim=-1)\n",
    "        if reduction == 'none':\n",
    "            pass\n",
    "        elif reduction == 'mean':\n",
    "            entropy_loss = entropy_loss.mean()\n",
    "        elif reduction == 'sum':\n",
    "            entropy_loss = entropy_loss.sum()\n",
    "        else:\n",
    "            raise ValueError(f'Unrecognized reduction: {reduction}')\n",
    "\n",
    "        combined_loss = policy_loss + value_loss + 0.05 * entropy_loss\n",
    "\n",
    "    if get_preds:\n",
    "        return policy_loss, value_loss, entropy_loss, combined_loss, logits_masked.argmax(dim=-1)\n",
    "    else:\n",
    "        return policy_loss, value_loss, entropy_loss, combined_loss\n",
    "\n",
    "test_metrics = {\n",
    "    'policy_loss': 0.,\n",
    "    'value_loss': 0.,\n",
    "    'entropy_loss': 0.,\n",
    "    'combined_loss': 0.,\n",
    "    'policy_accuracy': 0.\n",
    "}\n",
    "n_test_samples = 0.\n",
    "with torch.no_grad():\n",
    "    for test_tuple in tqdm(test_dataloader):\n",
    "        test_tuple = [t.to(device=DEVICE) for t in test_tuple]\n",
    "        state, action, result, head_locs, still_alive = test_tuple\n",
    "        policy_loss, value_loss, entropy_loss, combined_loss, preds = compute_losses(\n",
    "            *test_tuple,\n",
    "            reduction='mean',\n",
    "            get_preds=True\n",
    "        )\n",
    "        action_masked = action.view(-1)[still_alive.view(-1)]\n",
    "\n",
    "        test_metrics['policy_loss'] += policy_loss.detach().cpu().item()\n",
    "        test_metrics['value_loss'] += value_loss.detach().cpu().item()\n",
    "        test_metrics['entropy_loss'] += entropy_loss.detach().cpu().item()\n",
    "        test_metrics['combined_loss'] += combined_loss.detach().cpu().item()\n",
    "        test_metrics['policy_accuracy'] += preds.eq(action_masked).sum().cpu().item()\n",
    "        n_test_samples += still_alive.sum().cpu().item()\n",
    "\n",
    "    for key, metric in test_metrics.items():\n",
    "        test_metrics[key] = metric / n_test_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numeric-brown",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train metrics\n",
    "print(test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neither-great",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train metrics\n",
    "print(test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appreciated-blend",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test metrics\n",
    "print(test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "middle-volunteer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train metrics\n",
    "print(test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatty-hampton",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test metrics\n",
    "print(test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "postal-communist",
   "metadata": {},
   "outputs": [],
   "source": [
    "#env = kaggle_make('hungry_geese', debug=True)\n",
    "#env.reset(num_agents=4);\n",
    "replay_dict = read_json('/home/isaiah/Downloads/19528131.json')\n",
    "env = kaggle_make(\n",
    "    'hungry_geese',\n",
    "    configuration=replay_dict['configuration'],\n",
    "    steps=replay_dict['steps'],\n",
    "    info=replay_dict['info']\n",
    ")\n",
    "env.render(mode='ipython', height=700, width=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coated-prayer",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_tree = BasicMCTS(\n",
    "    action_mask_func=action_mask_func,\n",
    "    actor_critic_func=actor_critic_func,\n",
    "    terminal_value_func=terminal_value_func,\n",
    "    c_puct = 1.,\n",
    "    include_food=False\n",
    ")\n",
    "step_idx = 120\n",
    "state = env.steps[step_idx][0]\n",
    "state.update(env.steps[step_idx][0]['observation'])\n",
    "obs = Observation(state)\n",
    "light_env = make_from_state(\n",
    "    obs,\n",
    "    [Action[agent['action']] for agent in env.steps[-1]],\n",
    "    env.configuration\n",
    ")\n",
    "print(light_env.render_ansi())\n",
    "\n",
    "root_node = search_tree.run_mcts(\n",
    "    env=light_env,\n",
    "    n_iter=10000,\n",
    "    max_time=0.5\n",
    ")\n",
    "print(root_node.initial_policies)\n",
    "print(root_node.initial_values)\n",
    "print(root_node.q_vals)\n",
    "print(root_node.n_visits / root_node.n_visits.sum(axis=1, keepdims=True))\n",
    "print(root_node.n_visits.sum(axis=1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "answering-morris",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "search_tree = BasicMCTS(\n",
    "    action_mask_func=action_mask_func,\n",
    "    actor_critic_func=actor_critic_func,\n",
    "    terminal_value_func=terminal_value_func,\n",
    "    c_puct = np.sqrt(2.),\n",
    "    include_food=False\n",
    ")\n",
    "while not env.done:\n",
    "    state = env.steps[-1][0]\n",
    "    state.update(env.steps[-1][0]['observation'])\n",
    "    obs = Observation(state)\n",
    "    light_env = make_from_state(\n",
    "        obs,\n",
    "        [Action[agent['action']] for agent in env.steps[-1]],\n",
    "        env.configuration\n",
    "    )\n",
    "    print(light_env.render_ansi())\n",
    "    \n",
    "    csr = light_env.canonical_string_repr(include_food=search_tree.include_food)\n",
    "    for key in list(search_tree.nodes.keys()):\n",
    "        if key.startswith(f'S: {obs.step - 1}') or (key.startswith(f'S: {obs.step}') and key != csr):\n",
    "            del search_tree.nodes[key]\n",
    "    root_node = search_tree.run_mcts(\n",
    "        env=light_env,\n",
    "        n_iter=10000,\n",
    "        max_time=0.3\n",
    "    )\n",
    "    print(root_node.n_visits)\n",
    "    print(int(root_node.n_visits.sum() / 4))\n",
    "    actions = root_node.get_improved_actions(0.)\n",
    "    env.step([tuple(Action)[a].name for a in actions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loose-multiple",
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_critic_func(env.steps[-12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "victorian-network",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.render(mode='ipython', height=700, width=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "significant-lecture",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(root_node.n_visits)\n",
    "print(int(root_node.n_visits.sum() / 4))\n",
    "root_node.q_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dress-mongolia",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as colors\n",
    "for s, a, r, hl, alive in ag_dataloader:\n",
    "    square = np.ceil(np.sqrt(s.shape[1])).astype(np.int)\n",
    "    fig, axs = plt.subplots(square, square, figsize=(20,10))\n",
    "    ix = 0\n",
    "    for i in range(square):\n",
    "        for j in range(square):\n",
    "            ax = axs[i, j]\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "            eps = 1e-2\n",
    "            if ix < s.shape[1]:\n",
    "                pcm = ax.imshow(s[0, ix, :, :] + eps, norm=colors.LogNorm(vmin=eps, vmax=1.), cmap='gray')\n",
    "                ix += 1\n",
    "    fig.colorbar(pcm, ax = axs)\n",
    "    plt.show()\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
